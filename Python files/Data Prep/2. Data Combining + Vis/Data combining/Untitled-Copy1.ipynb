{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b3e7927-9d99-45b6-b970-9d720a59fb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time           timedelta64[ns]\n",
      "Price                    int64\n",
      "Volume                   int64\n",
      "source_file             object\n",
      "dtype: object\n",
      "                          Time  Price  Volume                    source_file\n",
      "0       0 days 00:00:10.881000    267       1  UoB_Set01_2025-01-02tapes.csv\n",
      "1       0 days 00:00:11.067000    269       1  UoB_Set01_2025-01-02tapes.csv\n",
      "2       0 days 00:00:11.222000    267       2  UoB_Set01_2025-01-02tapes.csv\n",
      "3       0 days 00:00:12.338000    270       2  UoB_Set01_2025-01-02tapes.csv\n",
      "4       0 days 00:00:13.733000    267       3  UoB_Set01_2025-01-02tapes.csv\n",
      "...                        ...    ...     ...                            ...\n",
      "3340496 0 days 08:29:54.706000    108       2  UoB_Set01_2025-07-01tapes.csv\n",
      "3340497 0 days 08:29:55.481000    108       2  UoB_Set01_2025-07-01tapes.csv\n",
      "3340498 0 days 08:29:56.349000    108       3  UoB_Set01_2025-07-01tapes.csv\n",
      "3340499 0 days 08:29:56.597000    108       2  UoB_Set01_2025-07-01tapes.csv\n",
      "3340500 0 days 08:29:56.597000    107       2  UoB_Set01_2025-07-01tapes.csv\n",
      "\n",
      "[3340501 rows x 4 columns]\n",
      "Time           timedelta64[ns]\n",
      "Price                    int64\n",
      "Volume                   int64\n",
      "source_file             object\n",
      "date                    object\n",
      "dtype: object\n",
      "                            Time  Price  Volume                    source_file\n",
      "0         0 days 00:00:10.881000    267       1  UoB_Set01_2025-01-02tapes.csv\n",
      "1         0 days 00:00:11.067000    269       1  UoB_Set01_2025-01-02tapes.csv\n",
      "2         0 days 00:00:11.222000    267       2  UoB_Set01_2025-01-02tapes.csv\n",
      "3         0 days 00:00:12.338000    270       2  UoB_Set01_2025-01-02tapes.csv\n",
      "4         0 days 00:00:13.733000    267       3  UoB_Set01_2025-01-02tapes.csv\n",
      "...                          ...    ...     ...                            ...\n",
      "3340496 180 days 08:29:54.706000    108       2  UoB_Set01_2025-07-01tapes.csv\n",
      "3340497 180 days 08:29:55.481000    108       2  UoB_Set01_2025-07-01tapes.csv\n",
      "3340498 180 days 08:29:56.349000    108       3  UoB_Set01_2025-07-01tapes.csv\n",
      "3340499 180 days 08:29:56.597000    108       2  UoB_Set01_2025-07-01tapes.csv\n",
      "3340500 180 days 08:29:56.597000    107       2  UoB_Set01_2025-07-01tapes.csv\n",
      "\n",
      "[3340501 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "#The directory to iterate over\n",
    "directory = \"/Users/gali/Downloads/Tapes\"\n",
    "\n",
    "#Sorted list of file names\n",
    "sorted_filenames = sorted(os.listdir(directory))\n",
    "\n",
    "#Iterating over each file in the directory in alphabetical order\n",
    "for filename in sorted(os.listdir(directory)):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.csv'):\n",
    "        #Reading the CSV file into a DataFrame\n",
    "        column_names = ['Time', 'Price', 'Volume']\n",
    "        df = pd.read_csv(file_path,names=column_names)\n",
    "        #Adding a new column to identify the file source (optional)\n",
    "        df['source_file'] = filename\n",
    "        #Appending the DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "        \n",
    "\n",
    "#Concatenating files\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "#combined_df = combined_df.drop(columns=['Index'])\n",
    "\n",
    "#Creating time as a time-delta object\n",
    "combined_df['Time'] = pd.to_timedelta(combined_df['Time'], unit='s')\n",
    "\n",
    "#Sorting by source_file and Time\n",
    "combined_df = combined_df.sort_values(by=['source_file', 'Time'])\n",
    "\n",
    "print(combined_df.dtypes)\n",
    "print(combined_df)\n",
    "\n",
    "combined_df['date'] = combined_df['source_file'].str.extract(r'(\\d{4}-\\d{2}-\\d{2})')\n",
    "print(combined_df.dtypes)\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "# 将时间列转换为 timedelta 类型\n",
    "combined_df['Time'] = pd.to_timedelta(combined_df['Time'])\n",
    "\n",
    "# 计算日期偏移量并调整时间列\n",
    "combined_df['Time'] = combined_df['Time'] + combined_df['date'] - combined_df['date'].min()\n",
    "\n",
    "# 删除辅助列\n",
    "combined_df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# 输出调整后的数据集\n",
    "print(combined_df)\n",
    "combined_df.to_csv('tapes.csv',index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #Calculating the offset for each day\n",
    "# #First, map each day to a unique number (0 for the first day, 1 for the second, etc.)\n",
    "# day_mapping = {day: idx for idx, day in enumerate(combined_df['source_file'].unique())}\n",
    "\n",
    "# #Applying the mapping to create a new column 'day_number'\n",
    "# combined_df['day_number'] = combined_df['source_file'].map(day_mapping)\n",
    "\n",
    "# #Calculating the time offset (in seconds) for each day and apply it\n",
    "# offset_per_day = 8.5 * 60 * 60  #8.5 hours in seconds\n",
    "# combined_df['adjusted_time'] = combined_df['Time'] + pd.to_timedelta(combined_df['day_number'] * offset_per_day, unit='s')\n",
    "\n",
    "\n",
    "# #Creating a binary column to indicate the start of a new day, for ARIMAX (unused)\n",
    "# combined_df['new_day_start'] = combined_df['day_number'].diff().fillna(1).astype(bool).astype(int)\n",
    "\n",
    "# time_taken = time.time() - time_start\n",
    "# print(\"Time taken: \" + str(time_taken))\n",
    "# print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72a8c5b7-a190-4ae8-a628-7fa018f636a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TimedeltaProperties' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m combined_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 提取每天最晚的时间点对应的数据\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m latest_data \u001b[38;5;241m=\u001b[39m combined_df\u001b[38;5;241m.\u001b[39mgroupby(combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate)\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 保留 'Time' 和 'Price' 列\u001b[39;00m\n\u001b[1;32m     11\u001b[0m latest_data \u001b[38;5;241m=\u001b[39m latest_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TimedeltaProperties' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "# 将 'Time' 列转换为 datetime 类型\n",
    "combined_df['Time'] = pd.to_timedelta(combined_df['Time'])\n",
    "\n",
    "# 按照 'Time' 列排序\n",
    "combined_df.sort_values(by='Time', inplace=True)\n",
    "\n",
    "# 提取每天最晚的时间点对应的数据\n",
    "latest_data = combined_df.groupby(combined_df['Time'].dt.date).tail(1)\n",
    "\n",
    "# 保留 'Time' 和 'Price' 列\n",
    "latest_data = latest_data[['Time', 'Price']]\n",
    "\n",
    "# 删除重复的时间点\n",
    "latest_data.drop_duplicates(subset='Time', inplace=True)\n",
    "\n",
    "# 重置索引\n",
    "latest_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 输出结果\n",
    "print(latest_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d733a9d7-6f08-445c-a422-766c45eaf40b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
